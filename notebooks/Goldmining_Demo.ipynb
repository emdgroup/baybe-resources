{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Gold Mining Optimization\n",
    "\n",
    "This notebook demonstrates Bayesian optimization using `BayBE` through a gold mining metaphor. We compare random search with `BayBE`'s intelligent optimization approach on a 2D landscape containing multiple gold-rich regions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The demo simulates searching for gold in an unknown 2D landscape:\n",
    "\n",
    "1. **Random Search Baseline**: Random sampling explores the landscape without strategy\n",
    "2. **`BayBE` Optimization**: Intelligent exploration that learns from each sample\n",
    "3. **Performance Comparison**: Quantitative comparison across multiple independent runs\n",
    "\n",
    "This example translates directly to real-world optimization problems such as:\n",
    "- Experimental parameter optimization (temperature, pH, concentration)\n",
    "- Formulation design (ingredient ratios)\n",
    "- Process optimization (reaction conditions)\n",
    "\n",
    "**Caution**:\n",
    "This notebook was developed for `BayBE` version 0.14.2. Although we do our best in keeping our breaking changes minimal and support outdated versions for a long time, this notebook might not be immediately applicable for other `BayBE` versions. If you install `BayBE` via the instructions in this repository, version 0.14.2 will thus be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a873f75",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "To install `BayBE` in AWS SageMaker, make sure that you have the `conda_python3` kernel activated. Then, run the following cell to install all required packages.\n",
    "Note that this might take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mamba install h5py\n",
    "%pip install baybe[simulation]==0.14.2 seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Setting up the Landscape\n",
    "\n",
    "We create a 2D landscape with multiple Gaussian peaks representing gold-rich regions. This simulates an unknown terrain where we want to find the highest gold concentration using as few samples as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GoldMine\n",
    "\n",
    "mine = GoldMine(grid_size=100, n_peaks=5, noise_level=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's visualize the landscape. The brighter regions indicate higher gold concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "fig_landscape = mine.plot(title=\"Gold Mining Landscape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Defining the Optimization Problem\n",
    "\n",
    "To compare random search with `BayBE`, we need to set up the optimization campaign components.\n",
    "\n",
    "### Define the Parameters\n",
    "\n",
    "We define two continuous parameters representing the 2D coordinates of our mining landscape. `BayBE` uses [`NumericalContinuousParameter`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.parameters.numerical.NumericalContinuousParameter.html) for parameters that can take any value within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalContinuousParameter\n",
    "\n",
    "parameters = [\n",
    "    NumericalContinuousParameter(name=\"x\", bounds=(0.0, 1.0)),\n",
    "    NumericalContinuousParameter(name=\"y\", bounds=(0.0, 1.0)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Define the Search Space\n",
    "\n",
    "The [`SearchSpace`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.searchspace.html) defines all possible parameter combinations that can be explored. We use [`SearchSpace.from_product`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.searchspace.core.SearchSpace.html#baybe.searchspace.core.SearchSpace.from_product) to create the Cartesian product of our parameters. In this example, our search space is effectively just the unit square in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "searchspace = SearchSpace.from_product(parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Define the Target and Objective\n",
    "\n",
    "The [`NumericalTarget`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.targets.numerical.NumericalTarget.html) represents the quantity we want to optimize (gold richness). We wrap it in a [`SingleTargetObjective`](https://emdgroup.github.io/baybe/0.14.2/userguide/objectives.html#singletargetobjective) since we're optimizing a single objective. By default, `BayBE` maximizes the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objectives import SingleTargetObjective\n",
    "\n",
    "target = NumericalTarget(name=\"gold_richness\")\n",
    "objective = SingleTargetObjective(target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "We now use a `RandomRecommender` to get 20 random recommendations and investigate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from baybe import Campaign\n",
    "from baybe.recommenders import RandomRecommender\n",
    "\n",
    "random_campaign = Campaign(\n",
    "    searchspace=searchspace,\n",
    "    objective=objective,\n",
    "    recommender=RandomRecommender(),\n",
    ")\n",
    "\n",
    "random_samples = []\n",
    "random_best_values = []\n",
    "current_best_random = -np.inf\n",
    "\n",
    "for _ in range(20):\n",
    "    random_rec = random_campaign.recommend(batch_size=1)\n",
    "    random_rec = mine.evaluate(random_rec)\n",
    "    random_campaign.add_measurements(random_rec)\n",
    "\n",
    "    random_gold_val = random_rec[\"gold_richness\"].iloc[0]\n",
    "    random_samples.append({\"x\": random_rec[\"x\"].iloc[0], \"y\": random_rec[\"y\"].iloc[0], \"value\": random_gold_val})\n",
    "    current_best_random = max(current_best_random, random_gold_val)\n",
    "    random_best_values.append(current_best_random)\n",
    "\n",
    "random_samples_df = pd.DataFrame(random_samples)\n",
    "\n",
    "fig_random = mine.plot(\n",
    "    samples=random_samples_df,\n",
    "    title=\"Random Search Samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### `BayBE` Optimization\n",
    "\n",
    "`BayBE` uses a surrogate model to predict the landscape and an acquisition function to decide where to sample next. It balances **exploration** (sampling uncertain regions) with **exploitation** (refining known promising areas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "baybe_campaign = Campaign(\n",
    "    searchspace=searchspace,\n",
    "    objective=objective,\n",
    ")\n",
    "\n",
    "baybe_samples = []\n",
    "baybe_best_values = []\n",
    "current_best_baybe = -np.inf\n",
    "\n",
    "for _i in range(20):\n",
    "    baybe_rec = baybe_campaign.recommend(batch_size=1)\n",
    "    baybe_rec = mine.evaluate(baybe_rec)\n",
    "    baybe_campaign.add_measurements(baybe_rec)\n",
    "\n",
    "    baybe_gold_val = baybe_rec[\"gold_richness\"].iloc[0]\n",
    "    baybe_samples.append({\"x\": baybe_rec[\"x\"].iloc[0], \"y\": baybe_rec[\"y\"].iloc[0], \"value\": baybe_gold_val})\n",
    "    current_best_baybe = max(current_best_baybe, baybe_gold_val)\n",
    "    baybe_best_values.append(current_best_baybe)\n",
    "\n",
    "baybe_samples_df = pd.DataFrame(baybe_samples)\n",
    "\n",
    "fig_baybe = mine.plot(\n",
    "    samples=baybe_samples_df,\n",
    "    title=\"BayBE Optimization Samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Single Run Comparison\n",
    "\n",
    "The learning curve below compares the best gold richness found so far at each iteration for both methods. The dashed line indicates the theoretical optimum (the maximum value in the landscape).\n",
    "\n",
    "Notice how `BayBE` typically finds high-richness regions faster and reaches a better final value compared to random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_comparison, ax_comparison = plt.subplots(figsize=(10, 6))\n",
    "iterations = np.arange(1, len(random_best_values) + 1)\n",
    "\n",
    "ax_comparison.plot(\n",
    "    iterations,\n",
    "    random_best_values,\n",
    "    \"o-\",\n",
    "    label=\"Random Search\",\n",
    ")\n",
    "ax_comparison.plot(\n",
    "    iterations,\n",
    "    baybe_best_values,\n",
    "    \"s-\",\n",
    "    label=\"BayBE Optimization\",\n",
    ")\n",
    "\n",
    "theoretical_max = np.max(mine.Z)\n",
    "ax_comparison.axhline(\n",
    "    y=theoretical_max,\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    alpha=0.7,\n",
    "    label=\"Theoretical Optimum\",\n",
    ")\n",
    "\n",
    "ax_comparison.set_xlabel(\"Number of Mining Attempts\", fontsize=12)\n",
    "ax_comparison.set_ylabel(\"Best Gold Richness Found\", fontsize=12)\n",
    "ax_comparison.set_title(\"Single Run: Random Search vs BayBE\", fontsize=14, fontweight=\"bold\")\n",
    "ax_comparison.legend(loc=\"lower right\", fontsize=10)\n",
    "ax_comparison.grid(True, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Running Simulated Campaigns\n",
    "\n",
    "A single run can be misleading due to randomness. To get a statistically robust comparison, we now run both methods multiple times using `BayBE`'s simulation utilities. This averages over the randomness in the optimization process and provides confidence intervals.\n",
    "\n",
    "We'll set up two scenarios:\n",
    "1. **Random Search**: Uses [`RandomRecommender`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.recommenders.pure.nonpredictive.sampling.RandomRecommender.html) for pure random sampling\n",
    "2. **`BayBE` Optimization**: Uses the default recommender for intelligent Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    \"Random Search\": Campaign(\n",
    "        searchspace=searchspace,\n",
    "        objective=objective,\n",
    "        recommender=RandomRecommender()\n",
    "    ),\n",
    "    \"BayBE Optimization\": Campaign(\n",
    "        searchspace=searchspace,\n",
    "        objective=objective,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Run the Simulations\n",
    "\n",
    "We use [`simulate_scenarios`](https://emdgroup.github.io/baybe/0.14.2/_autosummary/baybe.simulation.scenarios.html#baybe.simulation.scenarios.simulate_scenarios) to execute the optimization campaigns. This function runs each scenario multiple times and collects performance statistics.\n",
    "\n",
    "**Note**:\n",
    "When running the simulations, you may see warnings from `RandomRecommender` about unused objectives and measurements. This is expected and harmless. `RandomRecommender` samples points uniformly at random without considering the objective function or learning from previous measurements, which is why these inputs are ignored. The warnings serve as a reminder that random search does not utilize the optimization machinery that makes `BayBE` effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.simulation import simulate_scenarios\n",
    "\n",
    "N_DOE_ITERATIONS = 4  # Number of optimization iterations per run - incraese to ~30 for better results\n",
    "N_MC_ITERATIONS = 4  # Number of Monte Carlo runs - incraese to ~30 for better results\n",
    "\n",
    "results = simulate_scenarios(\n",
    "    scenarios,\n",
    "    mine.evaluate,\n",
    "    batch_size=1,\n",
    "    n_doe_iterations=N_DOE_ITERATIONS,\n",
    "    n_mc_iterations=N_MC_ITERATIONS,\n",
    ")\n",
    "\n",
    "results.rename(\n",
    "    columns={\n",
    "        \"Scenario\": \"Method\",\n",
    "        \"Num_Experiments\": \"Number of Mining Attempts\",\n",
    "        \"gold_richness_CumBest\": \"Best Gold Richness Found\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's visualize how both methods performed across multiple independent runs. The plot shows the mean performance (solid line) with confidence intervals (shaded regions) representing the variability across different optimization runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import backtest_plot\n",
    "\n",
    "backtest_plot(\n",
    "    df=results,\n",
    "    x=\"Number of Mining Attempts\",\n",
    "    y=\"Best Gold Richness Found\",\n",
    "    hue=\"Method\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The plot demonstrates that `BayBE` consistently outperforms random search by:\n",
    "- **Faster convergence**: `BayBE` reaches high-quality solutions with fewer mining attempts\n",
    "- **Better final performance**: `BayBE` typically finds regions with higher gold concentrations\n",
    "- **More reliable**: Smaller confidence intervals indicate more consistent performance\n",
    "\n",
    "This advantage comes from `BayBE`'s ability to build a surrogate model of the landscape and intelligently balance exploration (discovering new regions) with exploitation (refining known promising areas). In contrast, random search does not learn from previous observations and continues to sample uniformly across the entire search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLJB",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Real-World Applications\n",
    "\n",
    "This gold mining demo translates directly to optimization problems across various domains:\n",
    "\n",
    "| Demo Concept | Real-World Application |\n",
    "|--------------|------------------------|\n",
    "| Gold mining location (x, y) | Experimental parameters (temperature, pH, concentration) |\n",
    "| Gold richness value | Assay result, yield, purity, activity |\n",
    "| Number of attempts | Lab experiments (time and cost expensive) |\n",
    "| Random search | Traditional trial-and-error |\n",
    "| `BayBE` optimization | Smart experiment design |\n",
    "| Multiple Monte Carlo runs | Accounting for experimental variability |\n",
    "\n",
    "\n",
    "For more information, see the [`BayBE` documentation](https://emdgroup.github.io/baybe/)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "app_title": "Gold Mining Optimization",
    "width": "medium"
   },
   "marimo_version": "0.19.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
